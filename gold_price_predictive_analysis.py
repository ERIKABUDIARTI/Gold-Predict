# -*- coding: utf-8 -*-
"""Gold Price - Predictive Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y_vU5FOJvXYLhT5WSFS1rUDg10N_5DT8

# **Laporan Proyek Machine Learning**

Proyek Predictive Analysis: **Gold Price Prediction Dataset**
- Nama:**ERIKA BUDIARTI**
- Email: erika.analytic@gmail.com
- Id Dicoding:erika_budiarti
"""

# Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Melihat sekilas dataframe
gold_data = pd.read_csv('/content/gld_price_data.csv')
gold_data

# Menampilkan jumlah baris dan kolom pada dataframe
gold_data.shape

# Menampilkan informasi singkat dari dataframe
gold_data.info()

# Menampilkan statistik dataframe
gold_data.describe()

correlation = gold_data.corr()
correlation

# Menampilkan korelasi antar variable dalam heatmap
import matplotlib.pyplot as plt
plt.figure(figsize = (8,8))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f',annot=True, annot_kws={'size':10}, cmap='Greens')

# Visualisasi dengan pairplot
sns.pairplot(gold_data[['SPX','SLV','USO', 'GLD', 'EUR/USD']], plot_kws={"s": 5})

# Menampilkan missing value
gold_data.isna().sum()

# Menampilkan duplicated data
gold_data.duplicated().sum()

# Hitung Q1 dan Q3
Q1 = gold_data['GLD'].quantile(0.25)
Q3 = gold_data['GLD'].quantile(0.75)

# Hitung IQR
iqr = Q3 - Q1

# Hitung batas atas dan bawah outlier
lower_bound = Q1 - 1.5 * iqr
upper_bound = Q3 + 1.5 * iqr

# Cari outlier
outliers1 = gold_data[gold_data['GLD'] < lower_bound]
outliers2 = gold_data[gold_data['GLD'] > upper_bound]

# Cetak outlier
print(outliers1)
print(outliers2)

# Membersihkan Outlier
gold_data.loc[gold_data['GLD'] < lower_bound, 'GLD'] = gold_data['GLD'].median()
gold_data.loc[gold_data['GLD'] > upper_bound, 'GLD'] = gold_data['GLD'].median()

print(gold_data)

# Memisahkan Fitur dan Target
X = gold_data.drop(['Date','GLD'],axis=1)
y = gold_data['GLD']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=2)

# Normalisasi data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)

# Cek data normalisasi
print(X_train_scaled[:5])
print(X_test_scaled[:5])

lin_reg = LinearRegression()

lin_reg.fit(X_train, y_train)

param_grid = {'copy_X': [True, False],
              'fit_intercept': [True, False],
              'n_jobs': [None],
              'positive': [True, False]}

grid_search = GridSearchCV(lin_reg,
                           param_grid,
                           cv=5,
                           scoring='neg_mean_squared_error')

grid_search.fit(X, y)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f'Parameter terbaik untuk model Linear Regression adalah: {best_params}')
print(f'Skor Mean Squared Error (MSE) terbaik untuk model Regresi Linear adalah: {best_score}')

svr = SVR()

svr.fit(X_train, y_train)

param_grid = {'C': [1.0, 2.0],
              'cache_size': [100, 200],
              'coef0': [0.0, 0.1],
              'degree': [1, 3],
              'epsilon': [0.1, 0,2],
              'gamma': ['scale'],
              'kernel': ['rbf'],
              'max_iter': [-1],
              'shrinking': [True],
              'tol': [0.001, 0.01],
              'verbose': [False]}

grid_search = GridSearchCV(svr,
                           param_grid,
                           cv=5,
                           scoring='neg_mean_squared_error')

grid_search.fit(X, y)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f'Parameter terbaik untuk model SVM Regressor adalah: {best_params}')
print(f'Skor Mean Squared Error (MSE) terbaik untuk model SVM Regressor adalah: {best_score}')

metrics = pd.DataFrame(index=['Linear Regression','SVM Regressor'])

model_dict = {'Linear Regression': lin_reg, 'SVM Regressor': svr}

for name, model in model_dict.items():
    # Hitung MAE
    mae_train = mean_absolute_error(y_true=y_train, y_pred=model.predict(X_train))
    mae_test = mean_absolute_error(y_true=y_test, y_pred=model.predict(X_test))

    # Hitung MSE
    mse_train = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))
    mse_test = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))

    # Hitung R2
    r2_train = r2_score(y_true=y_train, y_pred=model.predict(X_train))
    r2_test = r2_score(y_true=y_test, y_pred=model.predict(X_test))

    # Simpan hasilnya dalam DataFrame
    metrics.loc[name, 'MAE Train'] = round(mae_train, 3)
    metrics.loc[name, 'MAE Test'] = round(mae_test, 3)
    metrics.loc[name, 'MSE Train'] = round(mse_train, 3)
    metrics.loc[name, 'MSE Test'] = round(mse_test, 3)
    metrics.loc[name, 'R2 Train'] = round(r2_train, 3)
    metrics.loc[name, 'R2 Test'] = round(r2_test, 3)

# Panggil DataFrame yang berisi MAE, MSE dan R2
display(metrics)

# Create subplots with 1 row and 3 columns
fig, axes = plt.subplots(2, 3, figsize=(18, 6))
colors = {'Linear Regression': 'blue', 'SVM Regressor': 'red'}

# Plot MAE Linear Regression vs MAE SVM Regressor
axes[0,0].bar(metrics.index, metrics['MAE Train'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[0,0].set_ylabel('MAE Value')
axes[0,0].set_title('MAE Train (Linear Regression vs SVM Regressor)')

# Plot MSE Linear Regression vs MSE SVM Regressor
axes[0,1].bar(metrics.index, metrics['MSE Train'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[0,1].set_ylabel('MSE Value')
axes[0,1].set_title('MSE Train (Linear Regression vs SVM Regressor)')

# Plot R2 Linear Regression vs R2 SVM Regressor
axes[0,2].bar(metrics.index, metrics['R2 Train'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[0,2].set_ylabel('R2 Value')
axes[0,2].set_title('R2 Train (Linear Regression vs SVM Regressor)')

# Plot MAE Linear Regression vs MAE SVM Regressor
axes[1,0].bar(metrics.index, metrics['MAE Test'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[1,0].set_ylabel('MAE Value')
axes[1,0].set_title('MAE Test (Linear Regression vs SVM Regressor)')

# Plot MSE Linear Regression vs MSE SVM Regressor
axes[1,1].bar(metrics.index, metrics['MSE Test'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[1,1].set_ylabel('MSE Value')
axes[1,1].set_title('MSE Test (Linear Regression vs SVM Regressor)')

# Plot R2 Linear Regression vs R2 SVM Regressor
axes[1,2].bar(metrics.index, metrics['R2 Test'].values, color=[colors['Linear Regression'], colors['SVM Regressor']])
axes[1,2].set_ylabel('R2 Value')
axes[1,2].set_title('R2 Test (Linear Regression vs SVM Regressor)')

# Adjust spacing between subplots
plt.tight_layout()

# Show the plots
plt.show()

pred = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict[name] = model.predict(pred).round(3)

pd.DataFrame(pred_dict)